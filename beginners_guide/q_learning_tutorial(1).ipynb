{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYMuqSTdZfjb"
      },
      "source": [
        "# Quantum Reinforcement Learning for TSP using Equivariant Quantum Circuits\n",
        "\n",
        "## Overview\n",
        "In this tutorial, we will explore how to use Qiskit to implement a Reinforcement Learning on `TorchConnector` class for solving the Traveling Salesperson Problem (TSP) using Equivariant Quantum Circuits.\n",
        "\n",
        "The tutorial is structured as follows:\n",
        "\n",
        "1. [Introduction](#1.-Introduction)\n",
        "2. [Data and representation](#2.-Data_and_representation)\n",
        "3. [Equivariant Quantum Circuit](#3.-Equivariant_Quantum_Circuit)\n",
        "4. [Q-Model](#4.-Q-Model)\n",
        "5. [Q-Learning: Neural Network Wrapper](#5.-Q-Learning:_Neural_Network_Wrapper)\n",
        "\n",
        "## 1. Introduction\n",
        "Equivariant Quantum Circuits (EQCs) [1] represent an innovative approach at the intersection of quantum computing and machine learning, designed to address problems in quantum information processing and optimization. These circuits leverage the principles of equivariance, a concept borrowed from group theory, to imbue quantum algorithms with symmetry-preserving properties.\n",
        "\n",
        "**References:**\n",
        "\n",
        "\\[1\\] Skolik et al., [Equivariant quantum circuits for learning on weighted graphs](https://arxiv.org/abs/2205.06109)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6Uu3aLZZfjd"
      },
      "source": [
        "## 2. Data and representation\n",
        "In this section, we'll begin by importing the necessary libraries and packages for handling data and creating representations. Proper setup is crucial for subsequent steps in our project.\n",
        "\n",
        "To get started, let's import the essential libraries and packages that will aid us in data handling and representation creation. These tools will lay the foundation for subsequent analyses and model development."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit\n",
        "!pip install qiskit_algorithms\n",
        "!pip install qiskit_machine_learning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51yrU_u5aPeO",
        "outputId": "9247470c-5d38-4001-c894-6f26642039d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-1.0.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rustworkx>=0.14.0 (from qiskit)\n",
            "  Downloading rustworkx-0.14.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.11.4)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.12)\n",
            "Collecting dill>=0.3 (from qiskit)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (2.8.2)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.2.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit) (4.11.0)\n",
            "Collecting symengine>=0.11 (from qiskit)\n",
            "  Downloading symengine-0.11.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (39.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.4/39.4 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.16.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0 (from stevedore>=3.0.0->qiskit)\n",
            "  Downloading pbr-6.0.0-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.5/107.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Installing collected packages: symengine, rustworkx, pbr, dill, stevedore, qiskit\n",
            "Successfully installed dill-0.3.8 pbr-6.0.0 qiskit-1.0.2 rustworkx-0.14.2 stevedore-5.2.0 symengine-0.11.0\n",
            "Collecting qiskit_algorithms\n",
            "  Downloading qiskit_algorithms-0.3.0-py3-none-any.whl (308 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.6/308.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: qiskit>=0.44 in /usr/local/lib/python3.10/dist-packages (from qiskit_algorithms) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.10/dist-packages (from qiskit_algorithms) (1.11.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit_algorithms) (1.25.2)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_algorithms) (0.14.2)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_algorithms) (1.12)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_algorithms) (0.3.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_algorithms) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_algorithms) (5.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_algorithms) (4.11.0)\n",
            "Requirement already satisfied: symengine>=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_algorithms) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit>=0.44->qiskit_algorithms) (1.16.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit>=0.44->qiskit_algorithms) (6.0.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit>=0.44->qiskit_algorithms) (1.3.0)\n",
            "Installing collected packages: qiskit_algorithms\n",
            "Successfully installed qiskit_algorithms-0.3.0\n",
            "Collecting qiskit_machine_learning\n",
            "  Downloading qiskit_machine_learning-0.7.2-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.8/97.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: qiskit>=0.44 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.0.2)\n",
            "Requirement already satisfied: qiskit-algorithms>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (0.3.0)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.11.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.25.2)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (5.9.5)\n",
            "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.2.2)\n",
            "Collecting fastdtw (from qiskit_machine_learning)\n",
            "  Downloading fastdtw-0.3.4.tar.gz (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (67.7.2)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (0.3.8)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_machine_learning) (0.14.2)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_machine_learning) (1.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_machine_learning) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_machine_learning) (5.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_machine_learning) (4.11.0)\n",
            "Requirement already satisfied: symengine>=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_machine_learning) (0.11.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->qiskit_machine_learning) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->qiskit_machine_learning) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit>=0.44->qiskit_machine_learning) (1.16.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit>=0.44->qiskit_machine_learning) (6.0.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit>=0.44->qiskit_machine_learning) (1.3.0)\n",
            "Building wheels for collected packages: fastdtw\n",
            "  Building wheel for fastdtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastdtw: filename=fastdtw-0.3.4-cp310-cp310-linux_x86_64.whl size=512612 sha256=066980144b6ac14eb29c4300c6d947724dcb0389b151dc71edc3403dac5aeb6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/c8/f7/c25448dab74c3acf4848bc25d513c736bb93910277e1528ef4\n",
            "Successfully built fastdtw\n",
            "Installing collected packages: fastdtw, qiskit_machine_learning\n",
            "Successfully installed fastdtw-0.3.4 qiskit_machine_learning-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "from scipy.spatial import distance_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "\n",
        "# Qiskit imports\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "from qiskit.circuit import QuantumCircuit, Parameter\n",
        "\n",
        "# Qiskit algorithms imports\n",
        "from qiskit_algorithms.utils import algorithm_globals\n",
        "\n",
        "# Qiskit ML imports\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "\"\"\" Note: the code is not optimized for GPU\n",
        "\"\"\"\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-18T17:59:15.850355600Z",
          "start_time": "2024-01-18T17:59:15.790621200Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwVXXgF4Zfje",
        "outputId": "db00c1d9-ee8a-4e9a-e12e-1e409386cff8"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code snippet generates a random fully connected graph by placing a specified number of nodes uniformly at random within a square. The graph is represented by coordinates in the two-dimensional plane, and pairwise Euclidean distances are computed to establish connections between nodes."
      ],
      "metadata": {
        "collapsed": false,
        "id": "gzJach3FZfjf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-18T17:59:15.879629200Z",
          "start_time": "2024-01-18T17:59:15.857354400Z"
        },
        "id": "QuCmbS7oZfjf"
      },
      "outputs": [],
      "source": [
        "def get_graph_mat(n=10, size=1):\n",
        "    \"\"\"Generate n nodes uniformly at random on a square and build a fully connected graph.\n",
        "\n",
        "    Args:\n",
        "        n (int): Number of nodes.\n",
        "        size (float): Size of the square.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Tuple containing coordinates matrix (N, 2) and pairwise Euclidean distances matrix (N, N).\n",
        "    \"\"\"\n",
        "    coords = size * np.random.uniform(size=(n, 2))\n",
        "    dist_mat = distance_matrix(coords, coords)\n",
        "    return coords, dist_mat\n",
        "\n",
        "def plot_graph(coords, mat):\n",
        "    \"\"\"Utility function to plot the fully connected graph.\n",
        "\n",
        "    Args:\n",
        "        coords (np.ndarray): Coordinates matrix.\n",
        "        mat (np.ndarray): Pairwise Euclidean distances matrix.\n",
        "    \"\"\"\n",
        "    n = len(coords)\n",
        "\n",
        "    plt.scatter(coords[:, 0], coords[:, 1], s=[50 for _ in range(n)])\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if j < i:\n",
        "                plt.plot([coords[i, 0], coords[j, 0]], [coords[i, 1], coords[j, 1]], 'b', alpha=0.7)\n",
        "                distance = mat[i, j]\n",
        "                mid_x = (coords[i, 0] + coords[j, 0]) / 2\n",
        "                mid_y = (coords[i, 1] + coords[j, 1]) / 2\n",
        "                plt.text(mid_x, mid_y, f'{distance:.2f}', color='red', fontsize=8, ha='center', va='center')\n",
        "\n",
        "def generate_networkx_graph(coords, mat):\n",
        "    \"\"\"Generate a NetworkX graph using coordinates and distances matrices.\n",
        "\n",
        "    Args:\n",
        "        coords (np.ndarray): Coordinates matrix.\n",
        "        mat (np.ndarray): Pairwise Euclidean distances matrix.\n",
        "\n",
        "    Returns:\n",
        "        nx.Graph: NetworkX graph.\n",
        "    \"\"\"\n",
        "    n = len(coords)\n",
        "    G = nx.Graph()\n",
        "\n",
        "    for i in range(n):\n",
        "        G.add_node(i, pos=(coords[i, 0], coords[i, 1]))\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(i + 1, n):\n",
        "            G.add_edge(i, j, weight=mat[i, j])\n",
        "\n",
        "    return G"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To illustrate the functionality, we provide an example that showcases the visualization of a randomly generated graph. In this example, the `generate_random_graph` function is used to create a fully connected graph by placing a specified number of nodes uniformly at random within a square."
      ],
      "metadata": {
        "collapsed": false,
        "id": "YU73Gb1cZfjf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-18T17:59:15.985122500Z",
          "start_time": "2024-01-18T17:59:15.883647300Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "BeTfNlAAZfjf",
        "outputId": "e41818fe-d73f-4187-c772-d6e53655f33b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# This is just an example:\n",
        "coords, W_np = get_graph_mat(n=5)\n",
        "\n",
        "# Generates a networkx graph.\n",
        "G = generate_networkx_graph(coords, W_np)\n",
        "\n",
        "# Draw NetworkX graph with edge weights (formatted to show two decimal places)\n",
        "pos = nx.get_node_attributes(G, 'pos')\n",
        "edge_labels = {(i, j): f'{weight:.2f}' for (i, j, weight) in G.edges(data='weight')}\n",
        "nx.draw(G, pos=pos, with_labels=True, font_weight='bold')\n",
        "nx.draw_networkx_edge_labels(G, pos=pos, edge_labels=edge_labels)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Equivariant Quantum Circuit\n",
        "\n",
        "In this section, we delve into the concept of Equivariant Quantum Circuits (EQCs) and explore their significance in quantum computing and machine learning. EQCs represent a unique approach that integrates principles from group theory to harness symmetries within quantum algorithms.\n",
        "\n",
        "Equivariance, a concept rooted in mathematics, plays a crucial role in EQCs. It involves transformations that preserve the inherent structure of quantum objects. In the context of quantum computing, equivariant transformations maintain symmetries within the quantum state space.\n",
        "\n",
        "Symmetry is a fundamental concept in quantum computing. EQCs aim to exploit symmetries to enhance the efficiency of quantum algorithms, particularly in addressing complex optimization problems.\n",
        "\n",
        "Equivariant Quantum Circuits often leverage principles from group theory and representation theory. These mathematical frameworks provide a systematic way to study symmetries and transformations in various algebraic structures.\n",
        "\n",
        "In this section, we provide a code snippet demonstrating the generation of Equivariant Quantum Circuits (EQCs) in `Qiskit`. The example showcases the implementation of a quantum circuit using the Qiskit framework, incorporating equivariant principles for potential applications in solving quantum computing tasks:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "8vP0itIhZfjg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def graph_encoding_circuit(edges, num_qubits, reps, params, insert_barriers=True) -> QuantumCircuit:\n",
        "    \"\"\"\n",
        "    Defines the graph encoding quantum circuit.\n",
        "\n",
        "    Parameters:\n",
        "    - edges: List of tuples representing edges in the graph.\n",
        "    - num_qubits: Number of qubits in the quantum circuit.\n",
        "    - reps: Number of layers (repetitions) in the circuit.\n",
        "    - params: Symbolic parameters for the circuit.\n",
        "    - insert_barriers: True if barriers are to be inserted for better visualization (optional).\n",
        "\n",
        "    Returns:\n",
        "    QuantumCircuit: The constructed quantum circuit.\n",
        "    \"\"\"\n",
        "    # Create a quantum circuit\n",
        "    circuit = QuantumCircuit(num_qubits)\n",
        "\n",
        "    # Apply Hadamard gates to all qubits\n",
        "    circuit.h(range(num_qubits))\n",
        "\n",
        "    for rep in range(reps):\n",
        "        edge_w = params[rep][-1]\n",
        "\n",
        "        # Edge encoding\n",
        "        for edge_i, edge in enumerate(edges):\n",
        "            circuit.cx(edge[0], edge[1])\n",
        "            circuit.rz(edge_w[edge_i], edge[1])\n",
        "            circuit.cx(edge[0], edge[1])\n",
        "\n",
        "        # Insert barrier for better visualization\n",
        "        if insert_barriers:\n",
        "            circuit.barrier()\n",
        "\n",
        "        # Vertex encoding\n",
        "        for q in range(num_qubits):\n",
        "            circuit.rx(params[rep][q], q)\n",
        "\n",
        "    return circuit"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-18T17:59:15.985122500Z",
          "start_time": "2024-01-18T17:59:15.970495600Z"
        },
        "id": "huWipwK5Zfjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see an example of this EQC with four qubits on single layer:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "9FruWgnpZfjg"
      }
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter(layer[0]_v[0]), Parameter(layer[0]_v[1]), Parameter(layer[0]_v[2]), Parameter(layer[0]_v[3])]\n",
            "[Parameter(layer[0]_v[0]), Parameter(layer[0]_v[1]), Parameter(layer[0]_v[2]), Parameter(layer[0]_v[3]), [Parameter(layer[0]_e[0]), Parameter(layer[0]_e[1]), Parameter(layer[0]_e[2]), Parameter(layer[0]_e[3]), Parameter(layer[0]_e[4]), Parameter(layer[0]_e[5])]]\n",
            "[[Parameter(layer[0]_v[0]), Parameter(layer[0]_v[1]), Parameter(layer[0]_v[2]), Parameter(layer[0]_v[3]), [Parameter(layer[0]_e[0]), Parameter(layer[0]_e[1]), Parameter(layer[0]_e[2]), Parameter(layer[0]_e[3]), Parameter(layer[0]_e[4]), Parameter(layer[0]_e[5])]]]\n"
          ]
        }
      ],
      "source": [
        "n_qubits = 4\n",
        "reps = 1\n",
        "edges = [(0, 1), (0, 2), (0,3), (1, 2), (1, 3), (2, 3)] # Hardcoded edges for testing.\n",
        "n_edges = len(edges)\n",
        "\n",
        "data_symbols = []\n",
        "for layer in range(reps):\n",
        "    data = [Parameter(f'layer[{layer}]_v[{qubit}]') for qubit in range(n_qubits)]\n",
        "    print(data)\n",
        "    data += [[Parameter(f'layer[{layer}]_e[{ew}]') for ew in range(n_edges)]]\n",
        "    print(data)\n",
        "    data_symbols.append(data)\n",
        "print(data_symbols)\n",
        "qc = graph_encoding_circuit(edges, n_qubits, reps, data_symbols)\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-18T17:59:16.195279200Z",
          "start_time": "2024-01-18T17:59:15.975029100Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBYzPye6Zfjg",
        "outputId": "664c76c4-9bd5-4fcc-e0a8-d607999b3e7a"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Q-Model\n",
        "\n",
        "The provided code defines a classical `EquivariantLayer` module, designed to interface with an Equivariant Quantum Circuit. This layer acts as a bridge to send parametrized variables to the quantum circuit for processing.\n",
        "\n",
        "Below is an explanation of the key components and functionality:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "_R3yEwO4Zfjh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class EquivariantLayer(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_input_params : int,\n",
        "            n_vars : int,\n",
        "            n_edges : int,\n",
        "            circuit_depth : int,\n",
        "            params : list):\n",
        "        \"\"\"\n",
        "        Initialize classical equivariant layer.\n",
        "        :param num_input_params: Number of input parameters.\n",
        "        :param n_vars: Number of variables.\n",
        "        :param n_edges: Number of edges.\n",
        "        :param circuit_depth: Depth of the circuit (repetitions).\n",
        "        :param params: List of parameters.\n",
        "        \"\"\"\n",
        "        super(EquivariantLayer, self).__init__()\n",
        "\n",
        "        # Define weights for the Layer\n",
        "        self.num_input_params = num_input_params * circuit_depth\n",
        "        self.num_params = 2 * circuit_depth\n",
        "        self.circuit_depth = circuit_depth\n",
        "\n",
        "        param_init = torch.ones(1, self.num_params, dtype=torch.float32)\n",
        "        self.params = torch.nn.Parameter(param_init)\n",
        "\n",
        "        self.param_repeats = []\n",
        "        for layer in range(self.circuit_depth):\n",
        "            self.param_repeats.append(n_vars)\n",
        "            self.param_repeats.append(n_edges)\n",
        "\n",
        "        alphabetical_params = sorted(params)\n",
        "        self.indices = [params.index(a) for a in alphabetical_params]\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Forward execution of the layer.\n",
        "        :param inputs: Input data.\n",
        "        :return: Returns the expectation values.\n",
        "        \"\"\"\n",
        "        repeated_params = self.params.repeat_interleave(torch.tensor(self.param_repeats))\n",
        "\n",
        "        repeat_inputs = inputs.repeat(self.circuit_depth, 1)\n",
        "\n",
        "        data_values = repeat_inputs * repeated_params\n",
        "        output = data_values[:, self.indices]\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-18T17:59:16.204901900Z",
          "start_time": "2024-01-18T17:59:16.201334900Z"
        },
        "id": "_1UFwQW_Zfjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `QModel` class presented below defines a neural network that serves as a parameterizer for the function Q. It integrates both classical and quantum layers, allowing seamless communication between classical and quantum components.\n",
        "\n",
        "Here's an overview of the key components and functionalities:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "NdhflMFoZfjh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class QModel(nn.Module):\n",
        "    def __init__(self, n_input_params : int, n_vars : int, num_edges_in_graph : int, n_layers : int,\n",
        "                 flattened_data_symbols : list, circuit : QuantumCircuit):\n",
        "        \"\"\"\n",
        "        The neural network that will parameterize the function Q.\n",
        "\n",
        "        :param n_input_params: Number of input parameters.\n",
        "        :param n_vars: Number of variables in the Equivariant Layer.\n",
        "        :param num_edges_in_graph: Number of edges in the graph.\n",
        "        :param n_layers: Number of repetitions/layers.\n",
        "        :param flattened_data_symbols: Flattened data symbols for the Equivariant Layer.\n",
        "        :param circuit: The Equivariant Quantum Circuit.\n",
        "        \"\"\"\n",
        "        super(QModel, self).__init__()\n",
        "        self.n_input_params = n_input_params\n",
        "        self.n_vars = n_vars\n",
        "        self.num_edges_in_graph = num_edges_in_graph\n",
        "        self.n_layers = n_layers\n",
        "        self.flattened_data_symbols = flattened_data_symbols\n",
        "\n",
        "        # Classical encoding layer.\n",
        "        self.encoding_layer = EquivariantLayer(num_input_params=self.n_input_params, n_vars=self.n_vars,\n",
        "                                               n_edges=self.num_edges_in_graph, circuit_depth=self.n_layers,\n",
        "                                               params=self.flattened_data_symbols)\n",
        "\n",
        "        # The Equivariant Quantum Circuit for Torch Connector.\n",
        "        self.circuit = circuit\n",
        "\n",
        "    def forward(self, input_data, observables) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward execution of the neural net.\n",
        "\n",
        "        :param input_data: Input data.\n",
        "        :return: Expectation values for all available nodes.\n",
        "        \"\"\"\n",
        "        encoding_output = self.encoding_layer(input_data)\n",
        "        qnn = TorchConnector(\n",
        "            EstimatorQNN(\n",
        "                circuit=self.circuit,\n",
        "                input_params=self.circuit.parameters,\n",
        "                observables=observables\n",
        "            )\n",
        "        )\n",
        "        expectation_values = qnn(encoding_output)\n",
        "\n",
        "        return expectation_values"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-18T17:59:16.330502Z",
          "start_time": "2024-01-18T17:59:16.206907300Z"
        },
        "id": "mmKvH8vFZfjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Q-Learning: Neural Network Wrapper\n",
        "\n",
        "In the following section, we introduce the `QFunction` class, serving as a wrapper around the neural network `QModel`. This class is designed to manipulate Traveling Salesperson Problem (TSP) partial solutions and efficiently translate them into tensors for processing by the neural network."
      ],
      "metadata": {
        "collapsed": false,
        "id": "FRGDQDqMZfji"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class QFunction():\n",
        "    def __init__(self, model, optimizer, lr_scheduler):\n",
        "        \"\"\"\n",
        "        Initializes the QFunction.\n",
        "\n",
        "        Parameters:\n",
        "        - model: The QNet model used for Q-value estimation.\n",
        "        - optimizer: The optimizer used for updating the model's parameters.\n",
        "        - lr_scheduler: Learning rate scheduler for adjusting the learning rate during training.\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.lr_scheduler = lr_scheduler\n",
        "        self.loss_fn = nn.MSELoss()\n",
        "\n",
        "    def predict(self, state_tsr, observables):\n",
        "        \"\"\"\n",
        "        Predicts Q-values for a given state and observables.\n",
        "\n",
        "        Parameters:\n",
        "        - state_tsr: Tensor representing the current state.\n",
        "        - observables: Additional observables relevant to the Q-value estimation.\n",
        "\n",
        "        Returns:\n",
        "        Tensor: Estimated Q-values for each action in the current state.\n",
        "        \"\"\"\n",
        "        # batch of 1 - only called at inference time\n",
        "        with torch.no_grad():\n",
        "            estimated_rewards = self.model(state_tsr, observables)\n",
        "        return estimated_rewards\n",
        "\n",
        "    def get_best_action(self, state_tsr, observables):\n",
        "        \"\"\"\n",
        "        Computes the best (greedy) action to take from a given state.\n",
        "\n",
        "        Parameters:\n",
        "        - state_tsr: Tensor representing the current state.\n",
        "        - observables: Additional observables relevant to the Q-value estimation.\n",
        "\n",
        "        Returns:\n",
        "        Tuple: Contains the ID of the next node and the corresponding estimated Q-Value.\n",
        "        \"\"\"\n",
        "        estimated_q_values = self.predict(state_tsr, observables=observables)\n",
        "        return torch.argmax(estimated_q_values), torch.max(estimated_q_values)\n",
        "\n",
        "    def batch_update(self, states_tsrs, observables_batch, actions, targets):\n",
        "        \"\"\"\n",
        "        Takes a gradient step using the loss computed on a batch of (states, Ws, actions, targets).\n",
        "\n",
        "        Parameters:\n",
        "        - states_tsrs: List of (single) state tensors.\n",
        "        - observables_batch: List of observables corresponding to the batch of states.\n",
        "        - actions: List of actions taken.\n",
        "        - targets: List of targets (resulting estimated rewards after taking the actions).\n",
        "\n",
        "        Returns:\n",
        "        float: The value of the loss incurred during the batch update.\n",
        "        \"\"\"\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # the rewards estimated by Q for the given actions\n",
        "        estimated_q_vals = []\n",
        "        for i in range(len(states_tsrs)):\n",
        "            estimated_q_vals.append(self.model(states_tsrs[i], observables_batch[i]))\n",
        "        estimated_q_vals = torch.stack(estimated_q_vals).squeeze(dim=1)  # [range(len(actions)), actions]\n",
        "        estimated_q_vals, _ = torch.max(estimated_q_vals, dim=1, keepdim=True)\n",
        "        estimated_q_vals = estimated_q_vals.squeeze(dim=1)\n",
        "\n",
        "        loss = self.loss_fn(estimated_q_vals, torch.tensor(targets, dtype=torch.float32, device=device))\n",
        "        loss_val = loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.lr_scheduler.step()\n",
        "\n",
        "        return loss_val"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-18T17:59:16.330502Z",
          "start_time": "2024-01-18T17:59:16.222932500Z"
        },
        "id": "NR-NhNtjZfji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1. Experiences and memory definition\n",
        "\n",
        "We'll now a tuple representing an experience, and the memory that contains such experiences. An experience is composed of a (state, action) tuple, and the corresponding \"next state\" and reward. The \"next state\" can be N step after the \"state\" in the case of N-step Q-learning. In experiences, we save states both in their tuple and tensor representations, in order to avoid computing these somewhat expensive translations after the experience has been stored."
      ],
      "metadata": {
        "collapsed": false,
        "id": "-VhDX44pZfji"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from collections import namedtuple\n",
        "import random\n",
        "\n",
        "# Named tuple to represent an experience in the replay memory\n",
        "Experience = namedtuple('Experience', ('state', 'state_tsr', 'action', 'reward', 'next_state', 'next_state_tsr'))\n",
        "\n",
        "class Memory(object):\n",
        "    def __init__(self, capacity):\n",
        "        \"\"\"\n",
        "        Initializes a replay memory.\n",
        "\n",
        "        Parameters:\n",
        "        - capacity: Maximum capacity of the replay memory.\n",
        "        \"\"\"\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "        self.nr_inserts = 0\n",
        "\n",
        "    def remember(self, experience):\n",
        "        \"\"\"\n",
        "        Records an experience in the replay memory.\n",
        "\n",
        "        Parameters:\n",
        "        - experience: An instance of the Experience namedtuple containing state, state tensor,\n",
        "                      action, reward, next state, and next state tensor.\n",
        "        \"\"\"\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = experience\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "        self.nr_inserts += 1\n",
        "\n",
        "    def sample_batch(self, batch_size):\n",
        "        \"\"\"\n",
        "        Samples a batch of experiences from the replay memory.\n",
        "\n",
        "        Parameters:\n",
        "        - batch_size: The number of experiences to sample in a batch.\n",
        "\n",
        "        Returns:\n",
        "        List: A list containing randomly sampled experiences from the replay memory.\n",
        "        \"\"\"\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the current number of experiences stored in the replay memory.\n",
        "\n",
        "        Returns:\n",
        "        int: The number of experiences stored in the replay memory.\n",
        "        \"\"\"\n",
        "        return min(self.nr_inserts, self.capacity)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-18T17:59:16.333038600Z",
          "start_time": "2024-01-18T17:59:16.229154600Z"
        },
        "id": "UHe0xIfGZfji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2. Training part\n",
        "\n",
        "#### 5.2.1. Hyperparameters and utilities\n",
        "\n",
        "In the following section, we outline the hyperparameters and utilities used for training a Q-learning agent to solve the Traveling Salesperson Problem (TSP). These parameters and functions play a crucial role in defining the learning process and guiding the agent's behavior within the environment."
      ],
      "metadata": {
        "collapsed": false,
        "id": "0ezNN9HjZfjj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "SEED = 1\n",
        "\n",
        "# Graph generation\n",
        "N_NODES = 7 # Number of nodes N\n",
        "N_LAYERS = 2 # Number of layers\n",
        "\n",
        "# Learning\n",
        "N_EPISODES = 500\n",
        "MEMORY_CAPACITY = 10000\n",
        "N_STEP_QL = 2 # Number of steps (n) in n-step Q-learning to wait before computing target reward estimate\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "GAMMA = 0.9\n",
        "INIT_LR = 5e-3\n",
        "LR_DECAY_RATE = 1. - 2e-5 # Learning rate decay.\n",
        "\n",
        "MIN_EPSILON = 0.1\n",
        "EPSILON_DECAY_RATE = 0.005 # Epsilon decay.\n",
        "\n",
        "FOLDER_NAME = './models'  # where to checkpoint the best models\n",
        "\n",
        "State = namedtuple('State', ('weight_mat', 'state_list', 'is_final', 'partial_tour', 'available_nodes'))\n",
        "\n",
        "def total_distance(tour, weight_mat):\n",
        "    \"\"\"\n",
        "    Computes the total distance of a given tour in a TSP.\n",
        "\n",
        "    Parameters:\n",
        "    - tour: List of edges representing the tour.\n",
        "    - weight_mat: Weight (distance) matrix for the graph.\n",
        "\n",
        "    Returns:\n",
        "    float: Total distance of the tour.\n",
        "    \"\"\"\n",
        "    total_dist = 0\n",
        "\n",
        "    for edge in tour:\n",
        "        # Extract the node indices from the edge\n",
        "        node1, node2 = edge\n",
        "\n",
        "        # Retrieve the weight (distance) from the adjacency matrix\n",
        "        dist = weight_mat[node1][node2]\n",
        "\n",
        "        # Add the distance to the total\n",
        "        total_dist += dist\n",
        "\n",
        "    # Check if the tour is a cycle (going through all vertices)\n",
        "    if len(set(node for edge in tour for node in edge)) == len(weight_mat):\n",
        "        # Add the distance from the last node to the first one\n",
        "        last_node, first_node = tour[-1][1], tour[0][0]\n",
        "        total_dist += weight_mat[last_node][first_node]\n",
        "\n",
        "    return total_dist\n",
        "\n",
        "def graph_to_list(nodes: list, edge_weights: dict, available_nodes: list[int]) -> list[float]:\n",
        "    \"\"\"\n",
        "    Converts a graph representation into a list of values.\n",
        "\n",
        "    Parameters:\n",
        "    - nodes: List of graph nodes.\n",
        "    - edge_weights: Dictionary of edge weights.\n",
        "    - available_nodes: List of available nodes.\n",
        "    - partial_tour: Partial tour of the TSP.\n",
        "\n",
        "    Returns:\n",
        "    list[float]: List of values representing the graph.\n",
        "    \"\"\"\n",
        "    vals = []\n",
        "    for node in nodes:\n",
        "        n = int(node in available_nodes)\n",
        "        vals.append(n * np.pi)\n",
        "\n",
        "    for w in edge_weights:\n",
        "        vals.append(np.arctan(w))\n",
        "\n",
        "    return vals\n",
        "\n",
        "def get_observables(partial_tour, available_nodes, weight_mat, nodes):\n",
        "    \"\"\"\n",
        "    Generates observables for the Quantum Circuit based on the partial tour.\n",
        "\n",
        "    Parameters:\n",
        "    - partial_tour: Partial tour of the TSP.\n",
        "    - available_nodes: List of available nodes.\n",
        "    - weight_mat: Weight (distance) matrix for the graph.\n",
        "    - nodes: List of graph nodes.\n",
        "\n",
        "    Returns:\n",
        "    list[SparsePauliOp]: List of observables for the Quantum Circuit.\n",
        "    \"\"\"\n",
        "    observables = []\n",
        "    last_edge = () if len(partial_tour) == 0 else partial_tour[-1]\n",
        "    last_node = 0 if len(last_edge) == 0 else last_edge[1]\n",
        "\n",
        "    for node in nodes:\n",
        "        if node in available_nodes:\n",
        "            observable = SparsePauliOp.from_sparse_list(\n",
        "                [(\"ZZ\", [last_node, node], weight_mat[last_node, node])],\n",
        "                num_qubits=N_NODES\n",
        "            )\n",
        "            observables.append(observable)\n",
        "        else:\n",
        "            observable = SparsePauliOp.from_sparse_list(\n",
        "                [(\"I\", [0], -10000)],\n",
        "                num_qubits=N_NODES\n",
        "            )\n",
        "            observables.append(observable)\n",
        "    return observables"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-18T17:59:16.333038600Z",
          "start_time": "2024-01-18T17:59:16.241006500Z"
        },
        "id": "3Mpkd80rZfjj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.2.2. Model Initialization\n",
        "\n",
        "In this section, we delve into the initialization process and setup for the EQC (Equivariant Quantum Circuit) model used in solving the Traveling Salesperson Problem (TSP) through Q-learning. The initialization involves creating the EQC model, setting hyperparameters, and defining utility functions to streamline the training process."
      ],
      "metadata": {
        "collapsed": false,
        "id": "n0sk9DjqZfjk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def generate_eqc_model(fully_connected_qubits):\n",
        "    \"\"\"\n",
        "    Generates the EQC model.\n",
        "\n",
        "    Parameters:\n",
        "    - fully_connected_qubits: List of fully connected qubits.\n",
        "\n",
        "    Returns:\n",
        "    QModel: EQC model.\n",
        "    \"\"\"\n",
        "    num_edges_in_graph = len(fully_connected_qubits)\n",
        "    n_input_params = N_NODES + num_edges_in_graph\n",
        "\n",
        "    data_symbols = []\n",
        "    for layer in range(N_LAYERS):\n",
        "        data = [Parameter(f'layer[{layer}]_v[{qubit}]') for qubit in range(N_NODES)]\n",
        "        data += [[Parameter(f'layer[{layer}]_e[{ew}]') for ew in range(num_edges_in_graph)]]\n",
        "        data_symbols.append(data)\n",
        "\n",
        "    circuit = graph_encoding_circuit(fully_connected_qubits, N_NODES, N_LAYERS, data_symbols)\n",
        "\n",
        "    flattened_data_symbols = []\n",
        "    for layer in data_symbols:\n",
        "        for item in layer:\n",
        "            if type(item) == list:\n",
        "                for symbol in item:\n",
        "                    flattened_data_symbols.append(str(symbol))\n",
        "            else:\n",
        "                flattened_data_symbols.append(str(item))\n",
        "\n",
        "    model = QModel(\n",
        "        n_input_params=n_input_params, n_vars=N_NODES,\n",
        "        num_edges_in_graph=num_edges_in_graph, n_layers=N_LAYERS,\n",
        "        flattened_data_symbols=flattened_data_symbols, circuit=circuit,\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "def init_model(fully_connected_qubits, fname=None):\n",
        "    \"\"\"\n",
        "    Initialize a new Q-function model.\n",
        "\n",
        "    Parameters:\n",
        "    - fully_connected_qubits: List of fully connected qubits.\n",
        "    - fname: If defined, load the model from the specified file.\n",
        "\n",
        "    Returns:\n",
        "    tuple: Tuple containing QFunction, QModel, optimizer, and lr_scheduler.\n",
        "    \"\"\"\n",
        "    Q_net = generate_eqc_model(fully_connected_qubits)\n",
        "    optimizer = optim.Adam(Q_net.parameters(), lr=INIT_LR)\n",
        "    lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=LR_DECAY_RATE)\n",
        "\n",
        "    if fname is not None:\n",
        "        checkpoint = torch.load(fname)\n",
        "        Q_net.load_state_dict(checkpoint['model'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
        "\n",
        "    Q_func = QFunction(Q_net, optimizer, lr_scheduler)\n",
        "    return Q_func, Q_net, optimizer, lr_scheduler\n",
        "\n",
        "def checkpoint_model(model, optimizer, lr_scheduler, loss,\n",
        "                     episode, avg_length):\n",
        "    \"\"\"\n",
        "    Checkpoints the current model.\n",
        "\n",
        "    Parameters:\n",
        "    - model: QModel instance.\n",
        "    - optimizer: Optimizer used for model training.\n",
        "    - lr_scheduler: Learning rate scheduler.\n",
        "    - loss: Loss value.\n",
        "    - episode: Current episode number.\n",
        "    - avg_length: Average length.\n",
        "\n",
        "    Saves a checkpoint file containing model parameters, optimizer state,\n",
        "    learning rate scheduler state, loss, episode, and average length.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(FOLDER_NAME):\n",
        "        os.makedirs(FOLDER_NAME)\n",
        "\n",
        "    fname = os.path.join(FOLDER_NAME, 'ep_{}'.format(episode))\n",
        "    fname += '_length_{}'.format(avg_length)\n",
        "    fname += '.tar'\n",
        "\n",
        "    torch.save({\n",
        "        'episode': episode,\n",
        "        'model': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'lr_scheduler': lr_scheduler.state_dict(),\n",
        "        'loss': loss,\n",
        "        'avg_length': avg_length\n",
        "    }, fname)\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-18T17:59:16.334561600Z",
          "start_time": "2024-01-18T17:59:16.248630400Z"
        },
        "id": "MDAUKR9BZfjk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.2.3. Training loop\n",
        "\n",
        "In this section, we present the Q-learning training loop responsible for solving the Traveling Salesperson Problem (TSP) using an Equivariant Quantum Circuit (EQC) model. The loop involves interacting with the environment, updating the model parameters, and tracking relevant metrics.\n",
        "\n",
        "The provided code initializes the necessary components, including the EQC model, optimizer, and replay memory. It then executes the Q-learning training loop for a specified number of episodes. Various metrics are collected and printed to monitor the training progress. Additionally, checkpointing ensures the preservation of the best-performing models.\n",
        "\n",
        "This training loop plays a vital role in training the EQC model to solve the TSP, combining exploration and exploitation strategies to efficiently navigate the solution space."
      ],
      "metadata": {
        "collapsed": false,
        "id": "m-IHKoLXZfjk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 0. Loss = -1.000 / median length = 2.959 / last = 2.9593 / epsilon = 1.0000 / lr = 0.0050\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (28) must match the size of tensor b (56) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-8d422797e626>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperience\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexperience\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_final\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                     _, best_reward = Q_func.get_best_action(experience.next_state_tsr,\n\u001b[0m\u001b[1;32m    155\u001b[0m                                                             get_observables(\n\u001b[1;32m    156\u001b[0m                                                                 \u001b[0mexperience\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_tour\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-6dfc1d942e73>\u001b[0m in \u001b[0;36mget_best_action\u001b[0;34m(self, state_tsr, observables)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mTuple\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mContains\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mID\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mestimated\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mValue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \"\"\"\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mestimated_q_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_tsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobservables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimated_q_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimated_q_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-6dfc1d942e73>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, state_tsr, observables)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# batch of 1 - only called at inference time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mestimated_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_tsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimated_rewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-6120eb9c8d6d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_data, observables)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mExpectation\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mall\u001b[0m \u001b[0mavailable\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \"\"\"\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mencoding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         qnn = TorchConnector(\n\u001b[1;32m     38\u001b[0m             EstimatorQNN(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-84c8be9be729>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mrepeat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircuit_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mdata_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepeat_inputs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrepeated_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (28) must match the size of tensor b (56) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "from itertools import combinations\n",
        "\n",
        "# seed everything for reproducible results first:\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "algorithm_globals.random_seed = SEED\n",
        "\n",
        "# Create module, optimizer, LR scheduler, and Q-function\n",
        "fully_connected_qubits = list(combinations(list(range(N_NODES)), 2))\n",
        "Q_func, Q_net, optimizer, lr_scheduler = init_model(fully_connected_qubits)\n",
        "\n",
        "# Create memory\n",
        "memory = Memory(MEMORY_CAPACITY)\n",
        "\n",
        "# Storing metrics about training:\n",
        "found_solutions = dict()  # episode --> (coords, W, solution)\n",
        "losses = []\n",
        "path_lengths = []\n",
        "best_lengths = []\n",
        "\n",
        "# keep track of median path length for model checkpointing\n",
        "current_min_med_length = float('inf')\n",
        "\n",
        "for episode in range(N_EPISODES):\n",
        "    # Sample a new random graph\n",
        "    nodes = range(0, N_NODES)\n",
        "    coords, weight_mat = get_graph_mat(n=N_NODES)\n",
        "    weight_mat_tsr = torch.tensor(weight_mat, dtype=torch.float32, requires_grad=False, device=device)\n",
        "\n",
        "    # current partial solution - a list of node index\n",
        "    partial_tour = []\n",
        "    initial_node = 0\n",
        "    available_nodes = list(range(1, N_NODES))\n",
        "\n",
        "    # current state (tuple and tensor)\n",
        "    edge_weights = []\n",
        "    for q in fully_connected_qubits:\n",
        "        edge_weights.append(weight_mat[q[0], q[1]])\n",
        "    current_state = graph_to_list(\n",
        "        nodes=nodes,\n",
        "        edge_weights=edge_weights,\n",
        "        available_nodes=available_nodes\n",
        "    )\n",
        "    current_state = State(weight_mat=weight_mat,state_list=current_state, is_final=len(available_nodes) == 0, partial_tour=partial_tour, available_nodes=copy.copy(available_nodes))\n",
        "    current_state_tsr = torch.tensor(current_state.state_list, dtype=torch.float32, requires_grad=False, device=device).unsqueeze(0)\n",
        "\n",
        "    # Keep track of some variables for insertion in replay memory:\n",
        "    states = [current_state]\n",
        "    states_tsrs = [current_state_tsr]  # we also keep the state tensors here (for efficiency)\n",
        "    rewards = []\n",
        "    actions = []\n",
        "\n",
        "    # current value of epsilon\n",
        "    epsilon = max(MIN_EPSILON, (1-EPSILON_DECAY_RATE)**episode)\n",
        "\n",
        "    nr_explores = 0\n",
        "    t = -1\n",
        "    while len(available_nodes) > 0:\n",
        "        t += 1 # time step of this episode\n",
        "\n",
        "        if epsilon >= random.random():\n",
        "            # explore\n",
        "            next_node = random.choice(available_nodes)\n",
        "            nr_explores += 1\n",
        "        else:\n",
        "            # exploit\n",
        "            observables = get_observables(\n",
        "                partial_tour=partial_tour,\n",
        "                available_nodes=available_nodes,\n",
        "                weight_mat=weight_mat,\n",
        "                nodes=nodes\n",
        "            )\n",
        "            next_node, est_reward = Q_func.get_best_action(current_state_tsr, observables)\n",
        "\n",
        "        if partial_tour:\n",
        "            last_element = partial_tour[-1][-1]\n",
        "        else:\n",
        "            last_element = 0\n",
        "        next_solution = partial_tour + [(last_element, next_node)]\n",
        "\n",
        "        # reward observed for taking this step\n",
        "        reward = -weight_mat[last_element, next_node]\n",
        "\n",
        "        available_nodes.remove(next_node)\n",
        "        next_state = graph_to_list(\n",
        "            nodes=nodes,\n",
        "            edge_weights=edge_weights,\n",
        "            available_nodes=available_nodes\n",
        "        )\n",
        "        next_state = State(\n",
        "            weight_mat=weight_mat,\n",
        "            state_list=next_state,\n",
        "            is_final=len(available_nodes) == 0,\n",
        "            partial_tour=next_solution,\n",
        "            available_nodes=copy.copy(available_nodes)\n",
        "        )\n",
        "        next_state_tsr = torch.tensor(next_state.state_list, dtype=torch.float32, requires_grad=False, device=device).unsqueeze(0)\n",
        "\n",
        "        # store rewards and states obtained along this episode:\n",
        "        states.append(next_state)\n",
        "        states_tsrs.append(next_state_tsr)\n",
        "        rewards.append(reward)\n",
        "        actions.append(next_node)\n",
        "\n",
        "        # store our experience in memory, using n-step Q-Learning:\n",
        "        if len(partial_tour) + 1 >= N_STEP_QL:\n",
        "            memory.remember(Experience(\n",
        "                state=states[-N_STEP_QL],\n",
        "                state_tsr=states_tsrs[-N_STEP_QL],\n",
        "                action=actions[-N_STEP_QL],\n",
        "                reward=sum(rewards[-N_STEP_QL:]),\n",
        "                next_state=next_state,\n",
        "                next_state_tsr=next_state_tsr\n",
        "            ))\n",
        "\n",
        "        if len(available_nodes) == 0:\n",
        "            for n in range(1, N_STEP_QL):\n",
        "                memory.remember(Experience(\n",
        "                    state=states[-n],\n",
        "                    state_tsr=states_tsrs[-n],\n",
        "                    action=actions[-n],\n",
        "                    reward=sum(rewards[-n:]),\n",
        "                    next_state=next_state,\n",
        "                    next_state_tsr=next_state_tsr\n",
        "                ))\n",
        "\n",
        "        # update state and current solution\n",
        "        current_state = next_state\n",
        "        current_state_tsr = next_state_tsr\n",
        "        partial_tour = next_solution\n",
        "\n",
        "        # Take a gradient step\n",
        "        loss = None\n",
        "        if len(memory) >= BATCH_SIZE and episode % 10 == 0:\n",
        "            experiences = memory.sample_batch(BATCH_SIZE)\n",
        "\n",
        "            batch_states_tsrs = [e.state_tsr for e in experiences]\n",
        "            batch_weight_mats = [e.state.weight_mat for e in experiences]\n",
        "            batch_actions = [e.action for e in experiences]\n",
        "            batch_targets = []\n",
        "            batch_observables = []\n",
        "\n",
        "            for i, experience in enumerate(experiences):\n",
        "                observables = get_observables(\n",
        "                    experience.state.partial_tour,\n",
        "                    available_nodes=experience.state.available_nodes,\n",
        "                    weight_mat=experience.state.weight_mat,\n",
        "                    nodes=nodes\n",
        "                )\n",
        "                target = experience.reward\n",
        "                if not experience.next_state.is_final:\n",
        "                    _, best_reward = Q_func.get_best_action(experience.next_state_tsr,\n",
        "                                                            get_observables(\n",
        "                                                                experience.next_state.partial_tour,\n",
        "                                                                available_nodes=experience.next_state.available_nodes,\n",
        "                                                                weight_mat=experience.next_state.weight_mat,\n",
        "                                                                nodes=nodes\n",
        "                                                            ))\n",
        "                    target += GAMMA * best_reward\n",
        "                batch_targets.append(target)\n",
        "                batch_observables.append(observables)\n",
        "\n",
        "            # print('batch targets: {}'.format(batch_targets))\n",
        "            loss = Q_func.batch_update(batch_states_tsrs, batch_observables, batch_actions, batch_targets)\n",
        "            losses.append(loss)\n",
        "\n",
        "            med_length = np.median(path_lengths[-100:])\n",
        "            if med_length < current_min_med_length:\n",
        "                current_min_med_length = med_length\n",
        "                checkpoint_model(Q_net, optimizer, lr_scheduler, loss, episode, med_length)\n",
        "\n",
        "    # Calculate total distance of tour and add it to path_lengths.\n",
        "    length = total_distance(partial_tour, weight_mat)\n",
        "    path_lengths.append(length)\n",
        "\n",
        "    # Get the best distance from networkx.\n",
        "    G = generate_networkx_graph(coords, weight_mat)\n",
        "    tsp_solution = nx.approximation.traveling_salesman_problem(G, cycle=True)\n",
        "    best_lengths.append(sum(G[u][v]['weight'] for u, v in zip(tsp_solution, tsp_solution[1:])))\n",
        "\n",
        "    # Print information from episode.\n",
        "    if episode % 10 == 0:\n",
        "        print('Ep %d. Loss = %.3f / median length = %.3f / last = %.4f / epsilon = %.4f / lr = %.4f' % (\n",
        "            episode, (-1 if loss is None else loss), np.median(path_lengths[-50:]), length, epsilon,\n",
        "            Q_func.optimizer.param_groups[0]['lr']))\n",
        "        found_solutions[episode] = (weight_mat, coords, [edge for edge in partial_tour])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-18T18:49:49.334037800Z",
          "start_time": "2024-01-18T17:59:16.269862Z"
        },
        "id": "sFXTzq_bZfjl",
        "outputId": "a0957a2a-5cd2-4cba-a535-e5b498cc8c9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.2.4. Inspect Training Metrics\n",
        "\n",
        "Let's examine the trends in loss and path length (represented by their moving averages) throughout the training process:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "K4R7jjQYZfjl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def _moving_avg(x, N=10):\n",
        "    return np.convolve(np.array(x), np.ones((N,))/N, mode='valid')\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(_moving_avg(path_lengths, 100))\n",
        "plt.ylabel('Average length')\n",
        "plt.xlabel('Iteration')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-18T18:49:49.453850300Z",
          "start_time": "2024-01-18T18:49:49.335041300Z"
        },
        "id": "6IpoTbXjZfjl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This following Python code snippet is designed to analyze the ratio of computed partial tour distances to the corresponding best path distances approximation. The goal is to visualize how well the computed solutions perform in comparison to the best-known solutions in a series of iterations or scenarios.\n",
        "\n",
        "It takes two lists as input: `path_lengths` and `best_lengths`. These lists represent the best path distances and the computed partial tour distances, respectively. The code calculates the ratio of each computed partial tour distance to the corresponding best path distance and plots the results.\n",
        "\n",
        "The resulting plot has the x-axis representing different iterations or scenarios, and the y-axis representing the ratio of the computed partial tour distance to the best path distance. This visualization provides insights into the relative performance of the computed solutions compared to the best-known solutions."
      ],
      "metadata": {
        "collapsed": false,
        "id": "anugUAC3Zfjm"
      }
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "ratios = [partial_tour_dist / best_dist for partial_tour_dist, best_dist in zip(path_lengths, best_lengths)]\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(_moving_avg(ratios, 100), linestyle='-', color='b')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Ratio to Best Path')\n",
        "plt.title('Ratio of Computed Partial Tour Distances to Best Path Distances')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-18T18:49:49.570267Z",
          "start_time": "2024-01-18T18:49:49.456788300Z"
        },
        "id": "T6oiRrObZfjm"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3 Evaluating the Best Model\n",
        "\n",
        "In this section, we re-run the best-performing model obtained during training and visualize the paths it generates. This allows us to assess the model's performance and observe the quality of the solutions it produces."
      ],
      "metadata": {
        "collapsed": false,
        "id": "tysAkWc7Zfjm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from itertools import combinations\n",
        "import copy\n",
        "\n",
        "def plot_graph(G, pos, edge_labels, edges_to_highlight=None, title=\"\", color='r'):\n",
        "    \"\"\"\n",
        "    Plot a graph using NetworkX, optionally highlighting specific edges.\n",
        "\n",
        "    Parameters:\n",
        "    - G: NetworkX graph object.\n",
        "    - pos: Dictionary of node positions generated by NetworkX layout algorithm.\n",
        "    - edge_labels: Dictionary of edge labels.\n",
        "    - edges_to_highlight: List of edges to highlight (optional).\n",
        "    - title: Title for the plot (optional).\n",
        "    - color: Edge color for highlighted edges (default is 'r' for red).\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    nx.draw(G, pos=pos, with_labels=True, font_weight='bold')\n",
        "    nx.draw_networkx_edge_labels(G, pos=pos, edge_labels=edge_labels)\n",
        "\n",
        "    if edges_to_highlight:\n",
        "        for edge in edges_to_highlight:\n",
        "            nx.draw_networkx_edges(G, pos=pos, edgelist=[edge], edge_color=color, width=2.0)\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Get file with smallest distance\n",
        "all_lengths_fnames = [f for f in os.listdir(FOLDER_NAME) if f.endswith('.tar')]\n",
        "shortest_fname = sorted(all_lengths_fnames, key=lambda s: float(s.split('.tar')[0].split('_')[-1]))[0]\n",
        "print('shortest avg length found: {}'.format(shortest_fname.split('.tar')[0].split('_')[-1]))\n",
        "\n",
        "# Load checkpoint\n",
        "fully_connected_qubits = list(combinations(list(range(N_NODES)), 2))\n",
        "Q_func, Q_net, optimizer, lr_scheduler = init_model(fully_connected_qubits, os.path.join(FOLDER_NAME, shortest_fname))\n",
        "\n",
        "# Generate example solutions\n",
        "NR_NODES = 7\n",
        "for sample in range(10):\n",
        "    coords, weight_mat = get_graph_mat(n=NR_NODES)\n",
        "    W = torch.tensor(weight_mat, dtype=torch.float32, requires_grad=False, device=device)\n",
        "\n",
        "    partial_tour = []\n",
        "    initial_node = 0\n",
        "    available_nodes = list(range(1, N_NODES))\n",
        "    nodes = range(0, N_NODES)\n",
        "\n",
        "    # current state (tuple and tensor)\n",
        "    edge_weights = []\n",
        "    for q in fully_connected_qubits:\n",
        "        edge_weights.append(weight_mat[q[0], q[1]])\n",
        "    current_state = graph_to_list(\n",
        "        nodes=nodes,\n",
        "        edge_weights=edge_weights,\n",
        "        available_nodes=available_nodes\n",
        "    )\n",
        "    current_state = State(weight_mat=weight_mat,state_list=current_state, is_final=len(available_nodes) == 0, partial_tour=partial_tour, available_nodes=copy.copy(available_nodes))\n",
        "    current_state_tsr = torch.tensor(current_state.state_list, dtype=torch.float32, requires_grad=False, device=device).unsqueeze(0)\n",
        "\n",
        "    while len(available_nodes) > 0:\n",
        "        observables = get_observables(\n",
        "                partial_tour=partial_tour,\n",
        "                available_nodes=available_nodes,\n",
        "                weight_mat=weight_mat,\n",
        "                nodes=nodes\n",
        "            )\n",
        "        next_node, est_reward = Q_func.get_best_action(current_state_tsr, observables)\n",
        "\n",
        "        available_nodes.remove(next_node)\n",
        "\n",
        "        if partial_tour:\n",
        "            last_element = partial_tour[-1][-1]\n",
        "        else:\n",
        "            last_element = 0\n",
        "        partial_tour = partial_tour + [(last_element, next_node)]\n",
        "\n",
        "        current_state = graph_to_list(\n",
        "            nodes=nodes,\n",
        "            edge_weights=edge_weights,\n",
        "            available_nodes=available_nodes\n",
        "        )\n",
        "        current_state = State(weight_mat=weight_mat,state_list=current_state, is_final=len(available_nodes) == 0, partial_tour=partial_tour, available_nodes=copy.copy(available_nodes))\n",
        "        current_state_tsr = torch.tensor(current_state.state_list, dtype=torch.float32, requires_grad=False, device=device).unsqueeze(0)\n",
        "\n",
        "    print(\"============================================\")\n",
        "    G = generate_networkx_graph(coords, weight_mat)\n",
        "    tsp_solution = nx.approximation.traveling_salesman_problem(G, cycle=True)\n",
        "\n",
        "    pos = nx.get_node_attributes(G, 'pos')\n",
        "    edge_labels = {(i, j): f'{weight:.2f}' for (i, j, weight) in G.edges(data='weight')}\n",
        "\n",
        "    # Plot tsp_edge_labels on a separate plot with green edges\n",
        "    total_distance = sum(G[u][v]['weight'] for u, v in zip(tsp_solution, tsp_solution[1:]))\n",
        "    print(\"Best graph length: \")\n",
        "    print(total_distance)\n",
        "    tsp_edge_labels = [(u, v) for u, v in zip(tsp_solution, tsp_solution[1:])]\n",
        "    plot_graph(G, pos, edge_labels, edges_to_highlight=tsp_edge_labels, title=\"Best Tour Approximation\", color='g')\n",
        "\n",
        "    # Plot converted_partial_tour on a separate plot with red edges\n",
        "    converted_partial_tour = [(int(start), int(end)) for start, end in partial_tour]\n",
        "    converted_partial_tour.append((converted_partial_tour[-1][1], converted_partial_tour[0][0]))\n",
        "    partial_tour_distance = sum(G[edge[0]][edge[1]]['weight'] for edge in converted_partial_tour)\n",
        "    print(\"Distance of the computed partial tour:\")\n",
        "    print(partial_tour_distance)\n",
        "    plot_graph(G, pos, edge_labels, edges_to_highlight=converted_partial_tour, title=\"Computed Partial Tour\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-18T18:49:54.955360700Z",
          "start_time": "2024-01-18T18:49:49.571257800Z"
        },
        "id": "c55xbsqpZfjm"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}